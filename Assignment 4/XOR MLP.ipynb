{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "    \n",
    "    def __init__ (self, input_size, output_size, num_layers, num_neurons, learning_rate):\n",
    "        # Set hyperparameters for MLP        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        # Create the matrix of neurons\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        \n",
    "        # Set weights and biases from input to first HL\n",
    "        self.weights.append(self.get_weights(num_neurons, input_size))\n",
    "        self.bias.append(self.get_weights(num_neurons, 1))\n",
    "        \n",
    "        # Set weights and biases for the next HLs\n",
    "        for i in xrange(1, num_layers):\n",
    "            self.weights.append(self.get_weights(num_neurons, num_neurons))\n",
    "            self.bias.append(self.get_weights(num_neurons, 1))\n",
    "        \n",
    "        # Set weights and biases from last HL to output\n",
    "        self.weights.append(self.get_weights(output_size, num_neurons))\n",
    "        self.bias.append(self.get_weights(output_size, 1))\n",
    "        \n",
    "        # Set rest of the params\n",
    "        self.sigmoid = np.vectorize(self.sigmoid)\n",
    "        self.sigmoid_prime = np.vectorize(self.sigmoid_prime)\n",
    "    #end init\n",
    "    \n",
    "    def get_weights(self,x,y):\n",
    "        return np.random.normal(0,1,(x,y))\n",
    "    #end get_weights\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        e_z = np.exp(-z)\n",
    "        output = 1.0/(1.0 + e_z)\n",
    "        return output\n",
    "    #end sigmoid\n",
    "    \n",
    "    def sigmoid_prime(self, z):\n",
    "        e_z = np.exp(-z)\n",
    "        output = e_z/((1.0 + e_z)**2)\n",
    "        return output\n",
    "    #end sigmoid_prime\n",
    "    \n",
    "    def feed_forward(self, mlp_input):\n",
    "        A = []\n",
    "        Z = []\n",
    "        output = mlp_input\n",
    "        for i in xrange(0, len(self.weights)):          # For each layer of MLP\n",
    "            \n",
    "#             print(\"INPUT\")\n",
    "#             print output\n",
    "        \n",
    "#             print(\"WEIGHTS\")\n",
    "#             print(self.weights[i])\n",
    "            out_len = len(output)\n",
    "            output = np.dot(self.weights[i], output) # Multiply by the weights\n",
    "            output = output/out_len\n",
    "#             print output\n",
    "            \n",
    "#             print(\"BIAS\")\n",
    "#             print(self.bias[i])\n",
    "            output += self.bias[i]                   # Add the biases\n",
    "            \n",
    "            Z.append(output)\n",
    "            output = self.sigmoid(output)            # Perform sigmoid function all\n",
    "                                                     # elements of the resultant matrix\n",
    "            A.append(output)\n",
    "            \n",
    "        return Z, A, output\n",
    "    # end feed forward\n",
    "    \n",
    "    def back_prop(self, n, mlp_input, Z, A, mlp_out, mlp_ground):\n",
    "        delta = np.multiply((mlp_out - mlp_ground),self.sigmoid_prime(Z[len(Z)-1])) \n",
    "        deltas = [delta]\n",
    "        for i in reversed(xrange(0,len(self.weights)-1)):\n",
    "            delta = np.multiply(np.dot(np.transpose(self.weights[i+1]),delta),self.sigmoid_prime(Z[i]))\n",
    "            deltas.insert(0,delta)\n",
    "        A.insert(0,mlp_input)\n",
    "        for i in reversed(xrange(0,len(self.weights))):\n",
    "            self.weights[i] = self.weights[i] - (self.learning_rate/n)*(np.dot(deltas[i],np.transpose(A[i])))\n",
    "            tmp = np.mean(deltas[i],axis=1)\n",
    "            tmp = np.matrix(tmp)\n",
    "            tmp = np.transpose(tmp)\n",
    "            self.bias[i] = self.bias[i] - ((self.learning_rate/n)*tmp)\n",
    "    # end back_prop\n",
    "    \n",
    "    def train(self, n, mlp_input, mlp_ground):\n",
    "        Z,A,mlp_out = self.feed_forward(mlp_input)\n",
    "        self.back_prop(n, mlp_input, Z, A, mlp_out, mlp_ground)    \n",
    "        return np.mean(abs(mlp_ground - mlp_out))\n",
    "    # end train\n",
    "        \n",
    "                            \n",
    "#     def toString(self):\n",
    "#         print \"PERCEPTRON STRUCTURE:\"\n",
    "#         print \"weights: \"\n",
    "#         print self.weights\n",
    "#         print \"bias: \"\n",
    "#         print self.bias\n",
    "#         return \" \"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4040.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL MLP OUTPUT AFTER EPOCH:\n",
      "TRAINED      :  [[ 0.00544923  0.99504783  0.99504814  0.00625011]]\n",
      "GROUND TRUTH :  [[0 1 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c4fbe0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYUyAEhSoQwAklQoA4AkFer/AZOP9s8bVcR8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x78a5160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XOR_INPUT = [[0,0,1,1],\n",
    "#              [0,1,0,1]]\n",
    "# XOR_OUTPUT = [0,1,1,0]\n",
    "\n",
    "XOR_INPUT = np.transpose(np.array([[0,0],[0,1],[1,0],[1,1]]))\n",
    "XOR_OUTPUT =  np.transpose(np.array([[0],[1],[1],[0]]))\n",
    "XOR_N = len(XOR_INPUT)\n",
    "\n",
    "epoch_time = 10000\n",
    "\n",
    "# input_size = 2\n",
    "# output_size = 1\n",
    "# num_layers = 1\n",
    "# num_neurons = 3\n",
    "# learning_rate = 20.0\n",
    "mlp = MLP(2, 1, 1, 3, 20.0)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(xrange(epoch_time)):\n",
    "    results.append(mlp.train(XOR_N, XOR_INPUT,XOR_OUTPUT))\n",
    "\n",
    "print \"FINAL MLP OUTPUT AFTER EPOCH:\"\n",
    "print \"TRAINED      : \", mlp.feed_forward(XOR_INPUT)[2]\n",
    "print \"GROUND TRUTH : \", XOR_OUTPUT\n",
    "\n",
    "plot(results)    \n",
    "\n",
    "# print \"\\n\\nMLP OUTPUT: \\n\", mlp_out\n",
    "# print \"Z\\n\",Z\n",
    "# print \"A\\n\",A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2L, 1L)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0,],[0,]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00544923]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.feed_forward([[0,],[0,]])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
